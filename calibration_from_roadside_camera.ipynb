{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "calibration.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOdPpsLOj4N/GCl/3w2xKc+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hector6298/Deep-Learning-Collab-notebooks/blob/master/calibration_from_roadside_camera.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XT9ToJ4gUg5M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive, files\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xt0Yz2rfxTUd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/zzh8829/yolov3-tf2\n",
        "%cd yolov3-tf2/\n",
        "#!pip install -r requirements-gpu.txt\n",
        "!mkdir outframes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJ87dTPXJ3JK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir data\n",
        "!cp \"/content/drive/My Drive/YOLO_weights/yolov3.weights\" \"data/yolov3.weights\"\n",
        "!python convert.py\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vK9lVpMuWBxw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import pathlib\n",
        "\n",
        "# Clone the tensorflow models repository if it doesn't already exist\n",
        "if \"models\" in pathlib.Path.cwd().parts:\n",
        "  while \"models\" in pathlib.Path.cwd().parts:\n",
        "    os.chdir('..')\n",
        "elif not pathlib.Path('models').exists():\n",
        "  !git clone --depth 1 \"https://github.com/tensorflow/models\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ZTqsgudWOMk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from absl import app, flags, logging\n",
        "from absl.flags import FLAGS\n",
        "from IPython.display import clear_output\n",
        "from skimage import feature, color, transform, io\n",
        "from google.colab.patches import cv2_imshow\n",
        "import io\n",
        "import scipy.misc\n",
        "import numpy as np\n",
        "from six import BytesIO\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "\n",
        "import tensorflow as tf\n",
        "from yolov3_tf2.models import (YoloV3, YoloV3Tiny)\n",
        "from yolov3_tf2.dataset import transform_images\n",
        "from yolov3_tf2.utils import draw_outputs\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import time\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o35lcVHi1099",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "OUTPATH = None\n",
        "CLASSES = ['car', 'truck', 'bus']\n",
        "NCLASSES = len(CLASSES)\n",
        "WEIGHTSPATH = \"/content/yolov3-tf2/checkpoints/yolov3.tf\"\n",
        "YOLOSIZE = 416\n",
        "TINY_YOLO = False\n",
        "VIDEOPATH = \"/content/drive/My Drive/speed_DS/center.avi\"\n",
        "app._run_init(['yolov3'], app.parse_flags_with_usage)\n",
        "\n",
        "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
        "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BjAavuM9Ppqe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def draw_outputs(img, outputs, class_names):\n",
        "    boxes, objectness, classes, nums = outputs\n",
        "    boxes, objectness, classes, nums = boxes[0], objectness[0], classes[0], nums[0]\n",
        "    wh = np.flip(img.shape[0:2])\n",
        "    boxpoints = []\n",
        "    for i in range(nums):\n",
        "        x1y1 = tuple((np.array(boxes[i][0:2]) * wh).astype(np.int32))\n",
        "        x2y2 = tuple((np.array(boxes[i][2:4]) * wh).astype(np.int32))\n",
        "        boxpoints.append((x1y1[0], x1y1[1], x2y2[0], x2y2[1]))\n",
        "        #img = cv2.rectangle(img, x1y1, x2y2, (255, 0, 0), 2)\n",
        "        #img = cv2.putText(img, '{} {:.4f}'.format(\n",
        "         ##  x1y1, cv2.FONT_HERSHEY_COMPLEX_SMALL, 1, (0, 0, 255), 2)\n",
        "    return img, boxpoints"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EM9iJcWxVq33",
        "colab_type": "text"
      },
      "source": [
        "##Get car keypoint neural network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrC9BVjIgxN9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install --upgrade tensorflow-hub\n",
        "import tensorflow_hub as hub"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X3S3bGo7gcYL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MODEL_URL = \"https://tfhub.dev/tensorflow/efficientnet/b0/feature-vector/1\"\n",
        "def get_model(input_shape, output_nodes):\n",
        "  inputs = tf.keras.layers.Input(shape=input_shape)\n",
        "  base_model = hub.KerasLayer(MODEL_URL, trainable=True)\n",
        "  regression_layer = tf.keras.layers.Dense(output_nodes, activation='tanh')\n",
        "\n",
        "  x = inputs\n",
        "  x = base_model(x)\n",
        "  x = regression_layer(x)\n",
        "\n",
        "  return tf.keras.Model(inputs=inputs, outputs=x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Q5oT92WgdZh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.models.load_model('/content/drive/My Drive/whole_keypointDNN112x112.h5',custom_objects={'KerasLayer':hub.KerasLayer})\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dSSojrU_u1L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "front_csv = pd.read_csv('/content/drive/My Drive/car_measures/front_side2.csv')\n",
        "back_csv = pd.read_csv('/content/drive/My Drive/car_measures/back_side2.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_NyibWrVvVu",
        "colab_type": "text"
      },
      "source": [
        "##Get Object detection network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJc_lTH5bzZC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "yolo = YoloV3(classes=80)\n",
        "\n",
        "yolo.load_weights(WEIGHTSPATH)\n",
        "logging.info('weights loaded')\n",
        "\n",
        "class_names = CLASSES\n",
        "logging.info('classes loaded')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wRibOMHfY5m9",
        "colab_type": "text"
      },
      "source": [
        "##Car crops flow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASVt6_Ap6koZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "times = []\n",
        "vid = cv2.VideoCapture(VIDEOPATH)\n",
        "out = None\n",
        "fps = int(vid.get(cv2.CAP_PROP_FPS))\n",
        "\n",
        "width = int(vid.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "height = int(vid.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "detections = 300\n",
        "frame = 0\n",
        "flag = True\n",
        "\n",
        "\n",
        "counter = 0\n",
        "\n",
        "\n",
        "cars = np.empty((detections,112,112,3))\n",
        "points_in_region = []\n",
        "crops_points = []\n",
        "crops_shapes = []\n",
        "cars_org = []\n",
        "sizes = []\n",
        "while True:\n",
        "    \n",
        "    _, img = vid.read()\n",
        "\n",
        "    if img is None:\n",
        "        logging.warning(\"Empty Frame\")\n",
        "        time.sleep(0.1)\n",
        "        continue\n",
        "        \n",
        "    if frame % 10 == 0:   \n",
        "        img_in = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        img_in = tf.expand_dims(img_in, 0)\n",
        "        img_in = transform_images(img_in, YOLOSIZE)\n",
        "\n",
        "        #t1 = time.time()\n",
        "        boxes_, scores_, classes_, nums_ = yolo.predict(img_in)\n",
        "        #print(nums.shape, scores.shape, classes.shape)\n",
        "        \n",
        "        img, boxPoints = draw_outputs(img, (boxes_, scores_, classes_, nums_), class_names)\n",
        "        #objects, velocities = tracker.update(boxPoints, fps)\n",
        "\n",
        "        for boxpoint in boxPoints:\n",
        "          x1, y1, x2, y2 = boxpoint\n",
        "          #CHECK ###########################################################################################################################\n",
        "          centroid = (int((y1 + y2)/2.0), int((x1 + x2)/2.0))                                                                              #\n",
        "          ##################################################################################################################################\n",
        "          points_in_region.append(centroid)\n",
        "          if counter < detections:\n",
        "            crop = img[boxpoint[1]-25:boxpoint[3]+26, boxpoint[0]-25:boxpoint[2]+26, :]\n",
        "            if crop.shape[0] > 112 and crop.shape[1] > 112:\n",
        "              cars_org.append(crop)\n",
        "              crops_shapes.append((crop.shape[0], crop.shape[1]))\n",
        "              #CHECH #########################################################################################################################\n",
        "              crops_points.append((y1,x1))                                                                                                   #\n",
        "              ################################################################################################################################\n",
        "              crop = cv2.resize(crop, (112,112))\n",
        "              x = crop.astype('float32') / 255.0\n",
        "              cars[counter] = x\n",
        "              sizes.append([boxpoint[3]-boxpoint[1], boxpoint[2]-boxpoint[0]])\n",
        "              counter += 1\n",
        "          else:\n",
        "            flag = False\n",
        "            break\n",
        "        if not flag:\n",
        "          break\n",
        "        print(counter)\n",
        "    frame += 1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7qu97IRA0W5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.imshow(cars[2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCL8uQUKNIEc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = np.empty((detections, 20))\n",
        "batch_size = 64\n",
        "steps_per_ds = int(detections / batch_size)\n",
        "remainder_ds = detections % batch_size\n",
        "\n",
        "for ind in range(steps_per_ds):\n",
        "  preds = model(cars[(ind*batch_size):((ind+1)*batch_size)])\n",
        "  predictions[(ind*batch_size):((ind+1)*batch_size)] = preds.numpy()\n",
        "\n",
        "preds = model(cars[-remainder_ds:])\n",
        "predictions[-remainder_ds:] = preds.numpy()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHDkMuJWd7IZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample_img1 = cars[2]\n",
        "for i in range(0, 20, 2):\n",
        "  #print(i, i+1)\n",
        "  pt1 = predictions[2][i+1]*sample_img1.shape[0]\n",
        "  pt1 = pt1.astype(int)\n",
        "  pt2 = predictions[2][i]*sample_img1.shape[1]\n",
        "  pt2 = pt2.astype(int)\n",
        "  pt = (pt2, pt1)\n",
        "  sample_img2 = cv2.circle(sample_img1, pt, 2, (255,0,0), 2) \n",
        "plt.imshow(sample_img2)\n",
        "plt.show()\n",
        "print(pt)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wLXOpYO7PAj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def check_keypoint(csv,keypointInd, realPointInd):\n",
        "  global keypoints\n",
        "  global points\n",
        "  global realPoints\n",
        "\n",
        "  if keypoints[keypointInd] is not None:\n",
        "    points.append(keypoints[keypointInd])\n",
        "    realPoints[1].append((csv['x1'][realPointInd],csv['y1'][realPointInd],csv['z1'][realPointInd]))\n",
        "    realPoints[2].append((csv['x2'][realPointInd],csv['y2'][realPointInd],csv['z2'][realPointInd]))\n",
        "    realPoints[3].append((csv['x3'][realPointInd],csv['y3'][realPointInd],csv['z3'][realPointInd]))\n",
        "    realPoints[4].append((csv['x4'][realPointInd],csv['y4'][realPointInd],csv['z4'][realPointInd]))\n",
        "    realPoints[5].append((csv['x5'][realPointInd],csv['y5'][realPointInd],csv['z5'][realPointInd]))\n",
        "  #else:\n",
        "    #print(\"Nothing\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1C2r1yWBnLp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " '''\n",
        "'left front tire': 0,\n",
        "'right front tire': 1,\n",
        "'left back tire': 2,\n",
        "'right back tire': 3,\n",
        "'right headlight': 4,\n",
        "'left headlight': 5,\n",
        "'front plate': 6,\n",
        "'left rear lamp': 7,\n",
        "'right rear lamp': 8,\n",
        "'rear plate': 9\n",
        "'''\n",
        "\n",
        "f = open('/content/points.txt',\"w+\")\n",
        "\n",
        "for j in range(detections):\n",
        "\n",
        "  points = []\n",
        "  #counters = []\n",
        "  realPoints = {1 : [],\n",
        "                2 : [],\n",
        "                3 : [],\n",
        "                4 : [],\n",
        "                5 : []}\n",
        "\n",
        "  keypoints = { 0: None,\n",
        "                1: None,\n",
        "                2: None,\n",
        "                3: None,\n",
        "                4: None,\n",
        "                5: None,\n",
        "                6: None,\n",
        "                7: None,\n",
        "                8: None,\n",
        "                9: None}\n",
        "#crops_points \n",
        "#crops_shapes \n",
        "\n",
        "  prediction = predictions[j]\n",
        "  counter = 0\n",
        "  #print(f'working on detection {j}')\n",
        "  for i in range(0, 20, 2):\n",
        "    if prediction[i] >= 0 and prediction[i+1] >= 0:\n",
        "      # CHECK #############################################################################################################\n",
        "      pred_y = ((prediction[i+1]*crops_shapes[j][0]) + crops_points[j][0]) - height//2\n",
        "      pred_x = (prediction[i]*crops_shapes[j][1] + crops_points[j][1]) - width//2\n",
        "      ####################################################################################################################\n",
        "      #keypoints[i//2] = (pred_y, pred_x)\n",
        "      keypoints[i//2] = (pred_x, pred_y)\n",
        "      counter += 1\n",
        "  if counter >= 4:\n",
        "    #counters.append(counter)\n",
        "    #front\n",
        "    if keypoints[4] is not None or keypoints[5] is not None:\n",
        "      #front-right\n",
        "      if keypoints[3] is not None or keypoints[1] is not None:\n",
        "        check_keypoint(front_csv,4,1)\n",
        "        check_keypoint(front_csv,5,0)\n",
        "        check_keypoint(front_csv,3,6)\n",
        "        check_keypoint(front_csv,1,4)\n",
        "        check_keypoint(front_csv,6,2)\n",
        "      #front-left\n",
        "      elif keypoints[0] is not None or keypoints[2] is not None:\n",
        "        check_keypoint(front_csv,4,1)\n",
        "        check_keypoint(front_csv,5,0)\n",
        "        check_keypoint(front_csv,0,3)\n",
        "        check_keypoint(front_csv,2,5)\n",
        "        check_keypoint(front_csv,6,2)\n",
        "\n",
        "    #back\n",
        "    elif keypoints[7] is not None or keypoints[8] is not None:\n",
        "      #back-right\n",
        "      if keypoints[3] is not None or keypoints[1] is not None:\n",
        "        #search in back csv\n",
        "        check_keypoint(back_csv,3,4)\n",
        "        check_keypoint(back_csv,1,6)\n",
        "        check_keypoint(back_csv,7,0)\n",
        "        check_keypoint(back_csv,8,1)\n",
        "        check_keypoint(back_csv,9,2)\n",
        "      #back-left\n",
        "      elif keypoints[0] is not None or keypoints[2] is not None:\n",
        "        #seach in back csv\n",
        "        check_keypoint(back_csv,0,5)\n",
        "        check_keypoint(back_csv,2,3)\n",
        "        check_keypoint(back_csv,7,0)\n",
        "        check_keypoint(back_csv,8,1) \n",
        "        check_keypoint(back_csv,9,2)\n",
        "        f.write(str(len(points))+\"\\n\")\n",
        "\n",
        "    f.write(str(len(points))+\"\\n\")\n",
        "    for i in range(len(points)):\n",
        "      f.write(f\"{points[i][0]} {points[i][1]}\\n\")\n",
        "      f.write(f\"{realPoints[1][i][0]} {realPoints[1][i][1]} {realPoints[1][i][2]}\\n\")\n",
        "      f.write(f\"{realPoints[2][i][0]} {realPoints[2][i][1]} {realPoints[2][i][2]}\\n\")\n",
        "      f.write(f\"{realPoints[3][i][0]} {realPoints[3][i][1]} {realPoints[3][i][2]}\\n\")\n",
        "      f.write(f\"{realPoints[4][i][0]} {realPoints[4][i][1]} {realPoints[4][i][2]}\\n\")\n",
        "      f.write(f\"{realPoints[5][i][0]} {realPoints[5][i][1]} {realPoints[5][i][2]}\\n\")\n",
        "\n",
        "  else:\n",
        "    print(f\"Not enough points on instance {j}\")\n",
        "f.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5w2nPOi-ixSP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cat /content/points.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "suYZA2u9vYzi",
        "colab_type": "text"
      },
      "source": [
        "## Get focal and camera pose algorithm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_7qDsQJvOkM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir /content/p3pf\n",
        "!git clone https://github.com/caomw/p3pf.git /content/p3pf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKVwWjACL_CO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%writefile /content/p3pf/p3pf_example.cc\n",
        "#include <Eigen/Dense>\n",
        "#include <Eigen/StdVector>\n",
        "#include <glog/logging.h>\n",
        "\n",
        "#include <algorithm>\n",
        "#include <chrono>\n",
        "#include <fstream>\n",
        "#include <random>\n",
        "\n",
        "#include \"camera_pose.h\"\n",
        "#include \"eigen_helpers.h\"\n",
        "#include \"p3pf_params.h\"\n",
        "#include \"p3pf.h\"\n",
        "using namespace std;\n",
        "int num_car_types = 5;\n",
        "int main(int argc, char *argv[]) {\n",
        "  gflags::ParseCommandLineFlags(&argc, &argv, true);\n",
        "  google::InitGoogleLogging(argv[0]);\n",
        "\n",
        "   ofstream outfile;\n",
        "   outfile.open(\"/content/output.txt\");\n",
        "  // The original list of opening angles used for the experiments in the\n",
        "  // paper.\n",
        "  std::vector<double> opening_angles = { 0.5, 1.5, 2.5, 3.5, 4.5, 5.5, 6.5, 7.5,\n",
        "      8.5, 9.5, 10.5, 11.5, 12.5, 13.5, 14.5, 15.5, 16.5, 17.5, 18.5, 19.5,\n",
        "      20.5, 21.5, 22.5, 23.5, 24.5, 25.5, 26.5, 27.5, 28.5, 29.5, 30.5, 31.5,\n",
        "      32.5, 33.5, 34.5, 35.5, 36.5, 37.5, 38.5, 39.5, 40.5, 41.5, 42.5, 43.5,\n",
        "      44.5, 45.5, 46.5, 47.5, 48.5, 49.5, 50.5, 51.5, 52.5, 53.5, 54.5, 55.5,\n",
        "      56.5, 57.5, 58.5, 59.5, 60.5, 61.5, 62.5, 63.5, 64.5, 65.5, 66.5, 67.5,\n",
        "      68.5, 69.5, 70.5, 71.5, 72.5, 73.5, 74.5, 75.5, 76.5, 77.5, 78.5, 79.5,\n",
        "      80.5, 81.5, 82.5, 83.5, 84.5, 85.5, 86.5, 87.5, 88.5, 89.5, 90.5, 91.5,\n",
        "      92.5, 93.5, 94.5, 95.5, 96.5, 97.5, 98.5, 99.5};\n",
        "  std::vector<double> prior_probabilities = { 0.0019519, 0.00060173, 0.00044518,\n",
        "      0.0010176, 0.0048432, 0.0034343, 0.0077197, 0.0038012, 0.0034098,\n",
        "      0.0062228, 0.0046328, 0.0039968, 0.0050633, 0.0044176, 0.0109, 0.0062325,\n",
        "      0.0060466, 0.017308, 0.01993, 0.014945, 0.0065994, 0.0080915, 0.015024,\n",
        "      0.012196, 0.015298, 0.011917, 0.014877, 0.011536, 0.0083802, 0.0090161,\n",
        "      0.0080915, 0.010332, 0.011599, 0.0089868, 0.00839, 0.0093244, 0.0094515,\n",
        "      0.0127, 0.0094613, 0.0087569, 0.010621, 0.010763, 0.012118, 0.014549,\n",
        "      0.013189, 0.014353, 0.01563, 0.02813, 0.050389, 0.053666, 0.047938,\n",
        "      0.065119, 0.065642, 0.02904, 0.016261, 0.011364, 0.0088645, 0.0071718,\n",
        "      0.006394, 0.0055574, 0.0067609, 0.010704, 0.022083, 0.025263, 0.015508,\n",
        "      0.021892, 0.02358, 0.0093928, 0.0039528, 0.0026564, 0.0019813, 0.0021476,\n",
        "      0.0025586, 0.0023384, 0.001179, 0.0011301, 0.0010322, 0.00092461,\n",
        "      0.00077295, 0.00072892, 0.00075338, 0.00076806, 0.00068, 0.00089526,\n",
        "      0.00086101, 0.00082187, 0.00082187, 0.00088058, 0.00091972, 0.00089036,\n",
        "      0.00079252, 0.00076806, 0.00090015, 0.00088058, 0.0015214, 0.0020987,\n",
        "      0.0016829, 0.0012328, 0.00091972, 0.00061641 };\n",
        "  std::ifstream infile(\"/content/points.txt\");\n",
        "  while (!infile.eof()){\n",
        "    // Initializes the parameters of the p3pf algorithm.\n",
        "    p3pf::P3PfParameters p3pf_params;\n",
        "    p3pf_params.ransac_parameters_.failure_probability = 0.01;\n",
        "    p3pf_params.ransac_parameters_.min_inlier_ratio = 0.1;\n",
        "    p3pf_params.ransac_parameters_.squared_inlier_threshold = 10.0;\n",
        "    p3pf_params.ransac_parameters_.random_seed = 0;\n",
        "    p3pf_params.ransac_parameters_.use_T_1_1_test = true;\n",
        "\n",
        "\n",
        "    p3pf_params.cdf_inlier_ratios_ = {0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7,\n",
        "      0.8, 0.9, 1.0};\n",
        "\n",
        "\n",
        "    int points;\n",
        "    double x2d, y2d;\n",
        "    double x3d, y3d, z3d;\n",
        "    std::vector<Eigen::Vector2d> points2D;\n",
        "    std::vector<Eigen::Vector3d> *points3D = new std::vector<Eigen::Vector3d>[num_car_types];\n",
        "    \n",
        "    \n",
        "    if(  infile >> points ){\n",
        "    \n",
        "      for(int i = 0; i < points; i++){\n",
        "        infile >> x2d >> y2d;\n",
        "        points2D.push_back({x2d,y2d});\n",
        "\n",
        "        for(int j = 0; j < num_car_types; j++){\n",
        "          infile >> x3d >> y3d >> z3d;\n",
        "          points3D[j].push_back({x3d,y3d,z3d});\n",
        "        }\n",
        "      }\n",
        "    }\n",
        "\n",
        "    // Converts the opening angles used for sampling to focal length values.\n",
        "    p3pf_params.focal_length_values_ = opening_angles;\n",
        "    for (size_t i = 0; i < opening_angles.size(); ++i) {\n",
        "      p3pf_params.focal_length_values_[i] = 320.0\n",
        "          / tan(opening_angles[i] / 2.0 * M_PI / 180.0);\n",
        "    }\n",
        "\n",
        "    p3pf_params.prior_probabilities_ = prior_probabilities;\n",
        "\n",
        "    for(int i = 0; i < num_car_types; i++){\n",
        "      // Initializes and runs P3P(f).\n",
        "      p3pf::P3Pf p3pf;\n",
        "      p3pf.Init(p3pf_params);\n",
        "      p3pf::P3PfResult result;\n",
        "      std::chrono::high_resolution_clock::time_point t1 =\n",
        "          std::chrono::high_resolution_clock::now();\n",
        "      p3pf.ComputePose(points2D, points3D[i], &result);\n",
        "      std::chrono::high_resolution_clock::time_point t2 =\n",
        "          std::chrono::high_resolution_clock::now();\n",
        "      std::chrono::duration<double> run_time = std::chrono::duration_cast<\n",
        "          std::chrono::duration<double>>(t2 - t1);\n",
        "\n",
        "      /*\"\"\"\n",
        "      outfile << \"Found number of inliers: \" << result.num_inliers_ << endl;\n",
        "\n",
        "      outfile << \" Estimated \"\n",
        "                << \"focal length: \" << result.pose_.focal_length() << endl;\n",
        "      \"\"\"*/\n",
        "      Eigen::Vector3d t;\n",
        "      Eigen::Matrix3d R;\n",
        "      result.pose_.rotation_matrix(&R);\n",
        "      result.pose_.translation(&t);\n",
        "      Eigen::Vector3d c;\n",
        "      c = -R.transpose() * t;\n",
        "\n",
        "      /*\"\"\"\n",
        "      outfile << \"Computed camera center: \"\n",
        "                << c.transpose() << endl;\n",
        "      outfile << \"P3P(f) took \" << result.num_generated_random_samples_\n",
        "                << \" iterations to compute the pose\" << endl;\n",
        "      outfile << \"Running P3P(f) took \" << run_time.count() << \" seconds \" << endl;\n",
        "      \"\"\"*/\n",
        "      outfile << result.pose_.focal_length() << endl;\n",
        "      outfile << R(0,0) << \" \" << R(0,1) << \" \" << R(0,2) << \" \" << t(0) << endl;\n",
        "      outfile << R(1,0) << \" \" << R(1,1) << \" \" << R(1,2) << \" \" << t(1) << endl;\n",
        "      outfile << R(2,0) << \" \" << R(2,1) << \" \" << R(2,2) << \" \" << t(2) << endl;\n",
        "\n",
        "\n",
        "    }\n",
        "  }\n",
        "  return 0;\n",
        "}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQJLVO71Um1x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!sudo apt-get install -y scons\n",
        "!sudo apt-get install libeigen3-dev\n",
        "!sudo apt-get install -y libgoogle-glog-dev\n",
        "%cd /content/p3pf\n",
        "!scons\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lD5aYF3Jyt5_",
        "colab_type": "text"
      },
      "source": [
        "##Compute and retrieve results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1663JBgyfEs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!./p3pf_example"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5lW63iRoz46",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cat /content/output.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NRZ9m95BtyZ6",
        "colab_type": "text"
      },
      "source": [
        "##Filtering calibrations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5uoTmYlAfF0g",
        "colab_type": "text"
      },
      "source": [
        "Get calibrations into python"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZWYRFGBSfINf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "focals = []\n",
        "pose_mats = []\n",
        "mat = []\n",
        "with open(\"/content/output.txt\",\"r\") as calib_file:\n",
        "  contents = calib_file.readlines()\n",
        "  for i in range(len(contents)):\n",
        "    if i % 4 == 0:\n",
        "      focals.append(float(contents[i]))\n",
        "      if i != 0:\n",
        "        pose_mats.append(mat)\n",
        "      mat = []\n",
        "    else:\n",
        "      row = list(map(float,contents[i].split(' ')))\n",
        "      mat.append(row)\n",
        "pose_mats = np.array(pose_mats)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "So3V_w2ouAv8",
        "colab_type": "text"
      },
      "source": [
        "Road regions of interest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dB04rNTSt2ag",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "points_in_region = np.array(points_in_region)\n",
        "my, mx = np.mean(points_in_region[:,0]), np.mean(points_in_region[:,1])\n",
        "point_of_interest = (mx,my)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3PTu3J58Vy7",
        "colab_type": "text"
      },
      "source": [
        "Formulas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJPNfVcx8XS9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from numpy import linalg as LA\n",
        "def OrientationFilter(pose_mats, threshold):\n",
        "  \n",
        "  \"\"\"\n",
        "  Filter out outlier pose mats based on orientation of the z axis.\n",
        "  pose_mats: numpy ndarray of shape [None,3,4]. A batch of pose matrices P = [R|T]\n",
        "  threshold: Int that represents the percentage of pose matrices to keep\n",
        "  \"\"\"\n",
        "\n",
        "  assert len(pose_mats.shape) == 3 and pose_mats[0].shape == (3,4), f\"Shape is invalid, expected [None,3,3] got: {pose_mats.shape}\"\n",
        "  arccos_arr = np.array([])\n",
        "  #Take third column of pose matrix i.e. the Z axis of rotation\n",
        "  z = pose_mats[:,:,2]\n",
        "  zavg = np.mean(z, axis=0)\n",
        "  zavg_norm = LA.norm(zavg)\n",
        "  mapping_dict = dict()\n",
        "  for i in range(len(z)):\n",
        "    z_ = np.inner(z[i], zavg)\n",
        "    norms = LA.norm(z[i]) * zavg_norm\n",
        "    quotient = z_/norms\n",
        "    arccos_val = np.arccos(quotient)\n",
        "    arccos_arr = np.append(arccos_arr, arccos_val)\n",
        "    mapping_dict[arccos_val] = i\n",
        "  sorted_arccos = np.sort(arccos_arr)\n",
        "  sorted_arccos = sorted_arccos[:int((len(sorted_arccos)/100)*threshold)]\n",
        "  new_mats = []\n",
        "  for arccos in sorted_arccos:\n",
        "    new_mats.append(pose_mats[mapping_dict[arccos]])\n",
        "  new_mats = np.array(new_mats)\n",
        "  assert len(new_mats.shape) == 3, f\"Got invalid shape for output matrices, got: {new_mats.shape}\"\n",
        "  return  new_mats\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgdG6X-oj1CU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def reproject2Dto3D(point2D, focal_length, pose_mat, Z = 0):\n",
        "  \"\"\"\n",
        "  Reproject a image point into world points\n",
        "  point2D: tuple or array of 2 integers. Image coordinates [y,x]\n",
        "  focal_length: float. Camera focal length\n",
        "  pose_mat: numpy ndarray of shape [3,3]. The pose matrix P = [R|T]\n",
        "  Z: Known value of height from the road up in world points measures.\n",
        "\n",
        "  returns tuple of 3 integers. The world points\n",
        "  \"\"\"\n",
        "\n",
        "  assert pose_mat.shape == (3,4), f\"pose_mat should be of shape [3,3] got: {pose_mat.shape}\"\n",
        "  assert focal_length > 0, \"Expected positive focal_length value\"\n",
        "  assert Z >= 0, \"Expected positive or zero Z value\"\n",
        "\n",
        "  Xnum = (focal_length*pose_mat[0][1] - pose_mat[2][1]*point2D[0])*(Z*pose_mat[1][2]+pose_mat[1][3]) - (focal_length*pose_mat[1][1] - pose_mat[2][1]*point2D[1])*(Z*pose_mat[0][2]+pose_mat[0][0]) - (Z*pose_mat[2][2]+pose_mat[2][3])*(pose_mat[0][1]*point2D[1]-pose_mat[1][1]*point2D[0])\n",
        "  Xden = focal_length*pose_mat[0][0]*pose_mat[1][1] - focal_length*pose_mat[0][1]*pose_mat[1][0] - pose_mat[0][0]*pose_mat[2][1]*point2D[1] + pose_mat[0][1]*pose_mat[2][0]*point2D[1] + pose_mat[1][0]*pose_mat[2][1]*point2D[0] - pose_mat[1][1]*pose_mat[2][0]*point2D[0]\n",
        "  Ynum = -(focal_length*pose_mat[0][0]-pose_mat[2][0]*point2D[0])*(Z*pose_mat[1][2]+pose_mat[1][3]) + (focal_length*pose_mat[1][0]-pose_mat[2][0]*point2D[1])*(Z*pose_mat[0][2]+pose_mat[0][3]) + (Z*pose_mat[2][2]+pose_mat[2][3])*(pose_mat[0][0]*point2D[1]-pose_mat[1][0]*point2D[0])\n",
        "  X = Xnum/Xden\n",
        "  Y = Ynum/Xden\n",
        "  assert np.array([X,Y,Z]).shape == (3,), f\"Error: world point not getting expected shape, got {np.array([X,Y,Z]).shape}\"\n",
        "  return (X,Y,Z)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0DJl91Gj4lw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def distance2Camera(point3D, pose_mat):\n",
        "  \"\"\"\n",
        "  Compute distance from road to camera using euclidean distance.\n",
        "  point3D: tuple or array of 3 integers. World coordinates [X,Y,Z]\n",
        "  pose_mat: numpy ndarray of shape [3,3]. The pose matrix P = [R|T]\n",
        "  \"\"\"\n",
        "  \n",
        "  return np.sqrt((point3D[0]-pose_mat[0][3])**2 + (point3D[1]-pose_mat[1][3])**2 + (point3D[2]-pose_mat[2][3])**2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSK9JpU_J0Wy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def displacementFilter(pose_mats,p, focal, threshold):\n",
        "\n",
        "  \"\"\"\n",
        "  Filters pose matrices based on displacement produced from the same image point reprojected to world points for each pose matrix\n",
        "  pose_mats: numpy ndarray of shape [None,3,4]. A batch of pose matrices P = [R|T]\n",
        "  focal: float. Camera focal length\n",
        "  p: tuple of two ints. Image point corresponding to center of region of interest (the road)\n",
        "  threshold: Int that represents the percentage of pose matrices to keep\n",
        "  \"\"\"\n",
        "\n",
        "  assert len(pose_mats.shape) == 3 and pose_mats[0].shape == (3,4), f\"Shape is invalid, expected [None,3,3] got: {pose_mats.shape}\"\n",
        "  assert focal > 0, \"Expected positive focal_length value\"\n",
        "  assert threshold > 0 and threshold <= 100, f\"Expected a threshold value from 0 to 100, got: {threshold}\"\n",
        "\n",
        "  displacements_container = []\n",
        "  mapping_dict = dict()\n",
        "  new_mats = []\n",
        "  i = 0\n",
        "  for pose_mat in pose_mats:\n",
        "    reprojected_center = reproject2Dto3D(p,focal,pose_mat)\n",
        "    distance = distance2Camera(reprojected_center, pose_mat)\n",
        "    displacements_container.append(distance)\n",
        "    mapping_dict[distance] = i\n",
        "    i += 1\n",
        "  displacements_container.sort()\n",
        "  for i in range(int(len(displacements_container)*threshold/100)):\n",
        "    new_mats.append(pose_mats[mapping_dict[displacements_container[i]]])\n",
        "  new_mats = np.array(new_mats)\n",
        "  assert len(new_mats.shape) == 3, f\"Got invalid shape for output matrices, got: {new_mats.shape}\"\n",
        "  return new_mats\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8n_t7tBf_BAB",
        "colab": {}
      },
      "source": [
        "def median_displacement_posemat(pose_mats,p, focal):\n",
        "  assert len(pose_mats.shape) == 3 and pose_mats[0].shape == (3,4), f\"Shape is invalid, expected [None,3,3] got: {pose_mats.shape}\"\n",
        "  assert focal > 0, \"Expected positive focal_length value\"\n",
        "\n",
        "  \"\"\"\n",
        "  Similar fashion from displacement_filer, but pick median of the pose matrices with respect of their reprojection displacement\n",
        "  pose_mats: numpy ndarray of shape [None,3,4]. A batch of pose matrices P = [R|T]\n",
        "  focal: float. Camera focal length\n",
        "  p: tuple of two ints. Image point corresponding to center of region of interest (the road)\n",
        "  \"\"\"\n",
        "\n",
        "  displacements_container = []\n",
        "  mapping_dict = dict()\n",
        "  i = 0\n",
        "  for pose_mat in pose_mats:\n",
        "    reprojected_center = reproject2Dto3D(p,focal,pose_mat)\n",
        "    distance = distance2Camera(reprojected_center, pose_mat)\n",
        "    displacements_container.append(distance)\n",
        "    mapping_dict[distance] = i\n",
        "    i += 1\n",
        "  displacements_container.sort()\n",
        "  median = len(displacements_container)//2\n",
        "  \n",
        "  return pose_mats[mapping_dict[displacements_container[median]]]\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fSZnh5vyikHu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mat2axis_angle(rotation_mat, epsilon=0.01, epsilon2=0.1):\n",
        "  assert rotation_mat.shape == [3,3], \"not valid rotation matrix\"\n",
        "  if (abs(rotation[0][1]-rotation[1][0]) < epsilon)  and (abs(rotation[0][2]-rotation[2][0]) < epsilon) and (abs(rotation[1][2]-rotation[2][1])<epsilon):\n",
        "    if (abs(rotation[0][1]+rotation[1][0]) < epsilon2) and (abs(rotation[0][2]+rotation[2][0]) < epsilon2) and (abs(rotation[1][2]+rotation[2][1]) < epsilon2) and (abs(rotation[0][0]+rotation[1][1]+rotation[2][2]-3) < epsilon2):\n",
        "      return (0,1,0,0)\n",
        "\n",
        "    angle = np.pi\n",
        "    xx = (rotation[0][0]+1)/2\n",
        "    yy = (rotation[1][1]+1)/2\n",
        "    zz = (rotation[2][2]+1)/2\n",
        "    xy = (rotation[0][1]+rotation[1][0])/4\n",
        "    xz = (rotation[0][2]+rotation[2][0])/4\n",
        "    yz = (rotation[1][2]+rotation[2][1])/4\n",
        "\n",
        "    if (xx > yy) and (xx > zz):\n",
        "      if xx < epsilon:\n",
        "        x = 0\n",
        "        y = 0.7071\n",
        "        z = 0.7071\n",
        "      else:\n",
        "        x = math.sqrt(xx)\n",
        "        y = xy/x\n",
        "        z = xz/x\n",
        "    elif yy > zz:\n",
        "      if yy < epsilon:\n",
        "        x = 0.7071\n",
        "        y = 0\n",
        "        z = 0.7071\n",
        "      else:\n",
        "        x = xy/y\n",
        "        y = math.sqrt(yy)\n",
        "        z = yz/y\n",
        "    else:\n",
        "      if zz < epsilon:\n",
        "        x = 0.7071\n",
        "        y = 0.7071\n",
        "        z = 0\n",
        "      else:\n",
        "        x = xz/z\n",
        "        y = yz/z\n",
        "        z = math.sqrt(zz)\n",
        "    \n",
        "    return (angle,x,y,z)\n",
        "  s = math.sqrt( (rotation[2][1]-rotaion[1][2])*(rotation[2][1]-rotation[1][2])+(rotation[0][2]-rotation[2][0])*(rotation[0][2]-rotation[2][0])+(rotation[1][0]-rotation[0][1])*(rotation[1][0]-rotation[0][1]))\n",
        "  if abs(s) < 0.001:\n",
        "    s = 1\n",
        "    print(\"warning matrix is not orthogonal\")\n",
        "  angle = math.acos((rotation[0][0]+rotation[1][1]+rotation[2][2]-1)/2)\n",
        "  x = (rotation[2][1]-rotation[1][2])/s\n",
        "  y = (rotation[0][2]-rotation[2][0])/s\n",
        "  z = (rotation[1][0]-rotation[0][1])/s\n",
        "  return (angle,x,y,z)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SypQ7-J5M8Ct",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def axis_angle2matrix(axis, angle):\n",
        "  c = np.cos(angle)\n",
        "  s = np.sin(angle)\n",
        "  t = 1.0 - c\n",
        "  mag = LA.norm(axis)\n",
        "  if mag == 0:\n",
        "    raise \"Error, 0 magnitude\"\n",
        "  else:\n",
        "    axis = axis/mag\n",
        "  \n",
        "  m00 = c + pow(axis[0],2)*t\n",
        "  m11 = c + pow(axis[1],2)*t\n",
        "  m22 = c + pow(axis[2],2)*t\n",
        "\n",
        "  temp1 = axis[0]*axis[1]*t\n",
        "  temp2 = axis[2]*s\n",
        "  m10 =  temp1 + temp2\n",
        "  m01 = temp1 - temp2\n",
        "\n",
        "  temp1 = axis[0]*axis[2]*t\n",
        "  temp2 = axis[1]*s\n",
        "  m20 = temp1 - temp2\n",
        "  m02 = temp1 + temp2\n",
        "\n",
        "  temp1 = axis[1]*axis[2]*t\n",
        "  temp2 = axis[0]*s\n",
        "  m21 = temp1 + temp2\n",
        "  m12 = temp1 - temp2\n",
        "\n",
        "  rotation = [[m00,m01,m02],\n",
        "              [m10,m11,m12],\n",
        "              [m20,m21,m22]]\n",
        "  return rotation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mEtEeAz4ibai",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def average_rotations(rotations, epsilon, maxit=1000):\n",
        "  R = rotations[0]\n",
        "  max = len(rotations)\n",
        "  r = [0,0,0]\n",
        "  mean = [0,0,0,0]\n",
        "  angle = 0\n",
        "  while maxit < 1000:\n",
        "    for i in range(1,len(rotations)):\n",
        "      RTR = np.matmul(R,rotations[i])\n",
        "      axis_angle = mat2axis_angle(RTR)\n",
        "      log_vector = axis_angle[0]*[axis_angle[1],axis_angle[2],axis_angle[3]]\n",
        "      mean += axis_angle\n",
        "      r = r + log_vector\n",
        "    r = r/len(rotations)\n",
        "    mean = mean/len(rotations)\n",
        "    if LA.norm(r) < epsilon\n",
        "      return R\n",
        "    R_ = axis_angle2matrix(mean[1],mean[2],mean[3],mean[0]) \n",
        "    R = np.matmul(R,R_)\n",
        "  return R"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9tqXvWYFStz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from scipy.spatial.transform import Rotation\n",
        "def filterCalibrations(pose_mats, focal, p_org,frame_height, frame_width):\n",
        "  \"\"\"\n",
        "  Method for projection matrix filtration inspired by AutoCalib\n",
        "  pose_mats: numpy ndarray of shape [None,3,4]. A batch of pose matrices P = [R|T]\n",
        "  focal: float. Camera focal length\n",
        "  p: tuple of two ints. Image point corresponding to center of region of interest (the road)\n",
        "  \"\"\"\n",
        "  assert len(pose_mats.shape) == 3 and pose_mats[0].shape == (3,4), f\"Shape is invalid, expected [None,3,3] got: {pose_mats.shape}\"\n",
        "  assert focal > 0, \"Expected positive focal_length value\"\n",
        "  assert p_org[0] >= 0 and p_org[1] >=0, f\"Expected point p with positive or zero coordinates, got: {p}\"\n",
        "  p = [0,0]\n",
        "  p[0] = p_org[0] - frame_width/2\n",
        "  p[1] = p_org[1] - frame_height/2\n",
        "  new_mats = OrientationFilter(pose_mats,75)\n",
        "  new_mats = displacementFilter(new_mats, p, focal, 50)\n",
        "  new_mats = OrientationFilter(new_mats, 75)\n",
        "  rotations = new_mats[:,:,:-1]\n",
        "  #a vg_rotation = average_rotations(rotations,0.01)\n",
        "  rotations = Rotation.from_matrix(rotations)\n",
        "  mean_rotation = rotations.mean().as_matrix()\n",
        "  for i in range(len(new_mats)):\n",
        "    new_mats[i,:,:-1] = mean_rotation\n",
        "  estimate = median_displacement_posemat(pose_mats,p, focal)\n",
        "\n",
        "  return estimate\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "akPoM0Q0e-PU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def medianFocalLength(focal_length_array):\n",
        "  \"\"\"\n",
        "  Compute median of focal_lengths.\n",
        "  focal_length_array: Python tuple or list of floats. The array of focal length values.\n",
        "  \"\"\"\n",
        "  focal_length_array.sort()\n",
        "  length = len(focal_length_array)\n",
        "  if length %2:\n",
        "    final_focal = (focal_length_array[(length//2)+1] + focal_length_array[length//2])/2.\n",
        "  else:\n",
        "    final_focal = focal_length_array[length//2]\n",
        "  return final_focal"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENFCKpe2f4aW",
        "colab_type": "text"
      },
      "source": [
        "Filtering!!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdATUQW8f518",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final_focal_length = medianFocalLength(focals)\n",
        "print(final_focal_length)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s072H8tGmvry",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final_pose = filterCalibrations(pose_mats,final_focal_length,point_of_interest, height, width)\n",
        "print(final_pose)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}